# llm_utils.py の機能説明

## 概要

`llm_utils.py`は、LLM（大規模言語モデル）の呼び出しに関するユーティリティ機能を提供するモジュールです。LangChainとLangGraphを使用してLLM呼び出しを実装しており、マルチモーダル入力（テキストと画像）に対応し、複数のLLMプロバイダ（OpenRouter, Gemini等）をサポートしています。

## 主要な機能

### 設定の読み込み

`load_settings`関数は、settings.jsonからAPIキーとモデル情報を読み込みます。主な処理手順は以下の通りです：

1. パス設定の初期化
2. 設定ファイルの読み込み
3. 設定情報の返却
4. ファイルが見つからない場合は空の辞書を返却

### JSONレスポースのパースと検証

`parse_json_response`関数は、LLMのレスポンスからJSONを抽出し、スキーマに基づいて検証します。主な処理手順は以下の通りです：

1. マークダウンのコードブロックからJSONを抽出
2. コードブロックが見つからない場合は、テキスト全体からJSONブロックを検索
3. JSONブロックが見つからない場合は、テキスト全体をJSONとしてパース
4. スキーマが指定されている場合は、JSONの内容をスキーマに基づいて検証
5. 検証に失敗した場合はエラーログを出力
6. パースに失敗した場合はデフォルト値または生のコンテンツを返却

### LLM呼び出し

`call_llm`関数は、LangChainを使用してLLMを呼び出します。主な処理手順は以下の通りです：

1. 設定の読み込み
2. LLMプロバイダの選択（OpenRouter, Gemini等）
3. API情報の取得
4. LangChainのチャットモデルの初期化
5. メッセージの準備
   - LangChainのメッセージクラス（HumanMessage, AIMessage, SystemMessage, ToolMessage）を使用
   - システムプロンプトの追加（指定されている場合）
   - stateからのメッセージ履歴の取得と変換
   - 画像データの追加（ファイルデータがある場合）
   - ツール/関数呼び出しの処理（Gemini系の場合はtoolをsystemに読み替え）
6. LLMの呼び出し
7. 詳細なAPIログの保存（リクエスト・レスポンスの全内容を含む）
8. レスポンスのJSONパースとスキーマ検証
9. 結果の返却
10. エラー発生時はエラー情報を返却

## データフロー

1. **他のモジュール**から`call_llm`が呼び出されます
   - 入力: プロンプト、システムプロンプト、ファイルデータ
   - 処理: LLMの呼び出しとレスポンスのパース
   - 出力: パース済みのレスポンス

2. **call_llm**内で`load_settings`が呼び出されます
   - 入力: なし
   - 処理: 設定ファイルの読み込み
   - 出力: 設定情報

3. **call_llm**内で`parse_json_response`が呼び出されます
   - 入力: LLMからのレスポンス
   - 処理: JSONの抽出
   - 出力: パース済みのJSON

## 入力と出力

### load_settings

#### 入力
- なし

#### 出力
- **settings**: 設定情報（辞書）
  - **api**: API設定
    - **openrouter**: OpenRouter API設定
      - **url**: API URL
      - **api_key**: APIキー
      - **models**: モデル情報
        - **conversation**: 会話用モデル名

### parse_json_response

#### 入力
- **content**: LLMのレスポンス内容（文字列）
- **default_values**: パース失敗時のデフォルト値（辞書、オプション）

#### 出力
- **result**: パース済みのJSON（辞書）
  - パース成功時: 抽出されたJSON
  - パース失敗時: デフォルト値または`{"content": content}`

### call_llm

#### 入力
- **prompt**: プロンプト（文字列）
- **system_prompt**: システムプロンプト（文字列、オプション）
- **files_data**: 添付ファイルのデータリスト（リスト、オプション）
  - 各ファイルは以下の情報を含む辞書
    - **filename**: ファイル名
    - **type**: ファイルタイプ（画像など）
    - **content_type**: MIMEタイプ
    - **content**: ファイルのバイナリデータ
- **api_name**: APIログに記録する呼び出し元の名前（文字列、オプション）

#### 出力
- **result**: 処理結果（辞書）
  - 成功時: パース済みのLLMレスポンス
  - 失敗時: `{"error": エラーメッセージ}`

## エラー処理

- 設定ファイルが見つからない場合は警告を表示し、空の辞書を返します
- APIキーが設定されていない場合はエラーメッセージを返します
- JSONパースに失敗した場合はデフォルト値または生のコンテンツを返します
- LLM呼び出しに失敗した場合はエラー情報を返します

## 特記事項

- マルチモーダル入力（テキストと画像）に対応しています
- 画像データはBase64エンコードされてLLMに送信されます
- APIログが保存されます
- LangChainとLangGraphを使用してLLM呼び出しを実装しています
- OpenRouter APIを使用しています
